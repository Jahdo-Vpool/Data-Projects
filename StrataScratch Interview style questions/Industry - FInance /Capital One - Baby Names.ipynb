{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## A) Descriptive analysis\n",
    "1. Please describe the format of the data files. Can you identify any limitations or distortions of the data?\n",
    "2. What is the most popular name of all time? (Of either gender.)\n",
    "3. What is the most gender ambiguous name in 2013? 1945?\n",
    "4. Of the names represented in the data, find the name that has had the largest percentage increase in popularity since 1980. Largest decrease?\n",
    "5. Can you identify names that may have had an even larger increase or decrease in popularity?"
   ],
   "id": "243365e116025725"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Part 1 - Understanding the file\n",
    "\n",
    "- Q: Please describe the format of the data files. Can you identify any limitations or distortions of the data?"
   ],
   "id": "3dd3e14384e86844"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Data Format:\n",
    "\n",
    "    - The data is provided in comma-delimited text files (.TXT), one for each state.\n",
    "\n",
    "    - Each record contains five fields: State Code, Sex (M/F), Year of Birth, Name, and the number of occurrences.\n",
    "\n",
    "- Data Limitations & Distortions:\n",
    "\n",
    "    1. Exclusion of Uncommon Names: The most significant limitation is that names with fewer than 5 occurrences in a given state and year are completely omitted. This distorts the data by over-representing popular names and making it impossible to study the \"long tail\" of rare or unique names.\n",
    "\n",
    "    2. Inaccurate National Aggregates: As a direct result of the first point, summing the state data will not produce an accurate national count. The true national total for any name will be higher than what can be calculated from these files.\n",
    "\n",
    "    3. Source-Related Bias: The data is sourced exclusively from Social Security records. This means individuals born before the widespread adoption of Social Security in the mid-1930s, or those who never received a Social Security Number for other reasons, are not included. This particularly impacts the reliability of the data for the earliest years in the dataset."
   ],
   "id": "ef131988136a716a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Part 2 - Searching through the data\n",
    "\n",
    "- What is the most popular name of all time? (Of either gender.)"
   ],
   "id": "9df1c8030a0e494a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:54:57.828522Z",
     "start_time": "2025-07-11T16:54:57.825981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#### Import necessary libraries\n",
    "import os\n",
    "import glob             # Finds all the files ending with .txt\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ],
   "id": "a0d8c4c525f771e1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:54:59.182963Z",
     "start_time": "2025-07-11T16:54:57.848283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the data path from the environment variables\n",
    "path = os.getenv(\"DATA_PATH\")\n",
    "\n",
    "# Check if the path was loaded correctly\n",
    "if not path:\n",
    "    raise ValueError(\"DATA_PATH was not found!\")\n",
    "\n",
    "# Locate the files ending in .txt\n",
    "all_files = glob.glob(path + \"/*.TXT\")\n",
    "\n",
    "# Create an empty list for all the dataframes\n",
    "df_list = []\n",
    "\n",
    "# Provide the column names since the text files do not\n",
    "column_names = ['State','Gender','Birth_year','Name','Name_occurrence']\n",
    "\n",
    "# loop through all the text files and create a dataframe for each\n",
    "# Add each dataframe to the df_list\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, header=None, names=column_names)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Add dataframes together along the row (axis=0)\n",
    "# Show the dataframe\n",
    "names_df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "print(\"Data was successfully loaded!\")\n",
    "names_df\n"
   ],
   "id": "e1880915a182949a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data was successfully loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        State Gender  Birth_year     Name  Name_occurrence\n",
       "0          IN      F        1910     Mary              619\n",
       "1          IN      F        1910    Helen              324\n",
       "2          IN      F        1910     Ruth              238\n",
       "3          IN      F        1910  Dorothy              215\n",
       "4          IN      F        1910  Mildred              200\n",
       "...       ...    ...         ...      ...              ...\n",
       "6311499    DE      M        2021   Thiago                5\n",
       "6311500    DE      M        2021   Travis                5\n",
       "6311501    DE      M        2021     Troy                5\n",
       "6311502    DE      M        2021   Walker                5\n",
       "6311503    DE      M        2021     Zayn                5\n",
       "\n",
       "[6311504 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Birth_year</th>\n",
       "      <th>Name</th>\n",
       "      <th>Name_occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IN</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Mary</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IN</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Helen</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Ruth</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Dorothy</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IN</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Mildred</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311499</th>\n",
       "      <td>DE</td>\n",
       "      <td>M</td>\n",
       "      <td>2021</td>\n",
       "      <td>Thiago</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311500</th>\n",
       "      <td>DE</td>\n",
       "      <td>M</td>\n",
       "      <td>2021</td>\n",
       "      <td>Travis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311501</th>\n",
       "      <td>DE</td>\n",
       "      <td>M</td>\n",
       "      <td>2021</td>\n",
       "      <td>Troy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311502</th>\n",
       "      <td>DE</td>\n",
       "      <td>M</td>\n",
       "      <td>2021</td>\n",
       "      <td>Walker</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311503</th>\n",
       "      <td>DE</td>\n",
       "      <td>M</td>\n",
       "      <td>2021</td>\n",
       "      <td>Zayn</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6311504 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:54:59.485045Z",
     "start_time": "2025-07-11T16:54:59.215191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Groupby name and sum the occurrences each time it is found\n",
    "# Sort the names in descending order to determine max value\n",
    "total_name_counts = names_df.groupby('Name')['Name_occurrence'].sum()\n",
    "most_popular_name = total_name_counts.sort_values(ascending=False).index[0]\n",
    "print(f'The most popular name of all time is: {most_popular_name} with a total count of {total_name_counts.loc[most_popular_name]}')"
   ],
   "id": "b66416d56b8688c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most popular name of all time is: James with a total count of 5054074\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Part 3 - Boy or Girl\n",
    "- Q: What is the most gender ambiguous name in 2013? 1945?"
   ],
   "id": "18cc91f86ee6ae7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:54:59.515833Z",
     "start_time": "2025-07-11T16:54:59.512548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to isolate the names by a specific year\n",
    "def names_by_year(dataframe, column_name, year):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame to select rows for a specific year.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): The name of the column containing the year.\n",
    "        year (int): The year to filter by.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame containing only the data for the specified year.\n",
    "    \"\"\"\n",
    "    names_in_year = dataframe[dataframe[column_name] == year]\n",
    "    return names_in_year\n",
    "\n",
    "# Function to calculate the total for each name in a specific year\n",
    "def get_name_totals(dataframe_year, name_col, sex_col, count_col):\n",
    "    \"\"\"\n",
    "    Groups a DataFrame by name and sex to calculate the total count for each name.\n",
    "\n",
    "    Args:\n",
    "        dataframe_year (pd.DataFrame): The input DataFrame (e.g., names_2013).\n",
    "        name_col (str): The column name for the names.\n",
    "        sex_col (str): The column name for the sex/gender.\n",
    "        count_col (str): The column name for the counts/occurrences.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with the summed counts for each name/sex combination.\n",
    "    \"\"\"\n",
    "    # Group by the name and sex columns, then sum the count column for each group.\n",
    "    name_totals = dataframe_year.groupby([name_col, sex_col])[count_col].sum().reset_index()\n",
    "    return name_totals\n",
    "\n",
    "# Function to calculate the ambiguity score of the names in the dataframe\n",
    "def calculate_ambiguity_score(dataframe_name, female_col='F', male_col='M'):\n",
    "    \"\"\"\n",
    "    Calculates and adds Total, Min_count, and Ambiguity_score columns to a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataframe_name (pd.DataFrame): The input DataFrame. Must have columns for female and male counts.\n",
    "        female_col (str): The name of the column for female counts. Defaults to 'F'.\n",
    "        male_col (str): The name of the column for male counts. Defaults to 'M'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new columns added.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original DataFrame unexpectedly\n",
    "    df_copy = dataframe_name.copy()\n",
    "\n",
    "    # Calculate the total and minimum counts\n",
    "    df_copy['Total'] = df_copy[female_col] + df_copy[male_col]\n",
    "    df_copy['Min_count'] = df_copy[[female_col, male_col]].min(axis=1)\n",
    "\n",
    "    # Calculate the ambiguity score\n",
    "    df_copy['Ambiguity_score'] = df_copy['Min_count'] / df_copy['Total']\n",
    "\n",
    "    return df_copy"
   ],
   "id": "e076b46cc593a810",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:54:59.576585Z",
     "start_time": "2025-07-11T16:54:59.539681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use function to isolate the names by year\n",
    "names_2013 = names_by_year(names_df, 'Birth_year', 2013)\n",
    "names_1945 = names_by_year(names_df, 'Birth_year', 1945)\n",
    "\n",
    "# Use function to determine the total count for each name\n",
    "names_total_2013 = get_name_totals(names_2013, 'Name','Gender', 'Name_occurrence')\n",
    "names_total_1945 = get_name_totals(names_1945, 'Name','Gender', 'Name_occurrence')"
   ],
   "id": "f506b10485742a4d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:54:59.602731Z",
     "start_time": "2025-07-11T16:54:59.588336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create pivot table to place genders in separate columns\n",
    "ambiguity_df_2013 = names_total_2013.pivot_table(\n",
    "    index='Name',\n",
    "    columns='Gender',\n",
    "    values='Name_occurrence',\n",
    "    fill_value=0 # Replace NaN with a 0\n",
    ")\n",
    "\n",
    "ambiguity_df_1945 = names_total_1945.pivot_table(\n",
    "    index='Name',\n",
    "    columns='Gender',\n",
    "    values='Name_occurrence',\n",
    "    fill_value=0 # Replace NaN with a 0 for names that are exclusively M or F\n",
    ")"
   ],
   "id": "72e1b61cc344a0e9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:54:59.618131Z",
     "start_time": "2025-07-11T16:54:59.615257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if NaN or missing values were replaced with a zero\n",
    "ambiguity_df_2013.isnull().sum()"
   ],
   "id": "7c70dca6fb7d258",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "F    0\n",
       "M    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:54:59.653909Z",
     "start_time": "2025-07-11T16:54:59.648051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the function to determine the ambiguity score of each name for the desired year\n",
    "ambiguity_score_1945_df = calculate_ambiguity_score(ambiguity_df_1945, 'F', 'M')\n",
    "ambiguity_score_2013_df = calculate_ambiguity_score(ambiguity_df_2013, 'F', 'M')\n",
    "\n",
    "# Sort the rows in descending order and pull the top 10 names\n",
    "ten_most_ambiguous_names_2013 = ambiguity_score_2013_df.sort_values(by=['Ambiguity_score'], ascending=False).head(10)\n",
    "ten_most_ambiguous_names_1945 = ambiguity_score_1945_df.sort_values(by=['Ambiguity_score'], ascending=False).head(10)\n",
    "\n",
    "# Print the names with the highest ambiguity score for 2013 and 1945\n",
    "print(f'The most ambiguous name in the year 1945 was {ten_most_ambiguous_names_1945.index[0]}!\\n')\n",
    "print(f'The most ambiguous name in the year 2013 was {ten_most_ambiguous_names_2013.index[0]}!')"
   ],
   "id": "b0e5ff40ff953cd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most ambiguous name in the year 1945 was Maxie!\n",
      "\n",
      "The most ambiguous name in the year 2013 was Arlin!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Part 4 - Mr & Ms popular\n",
    "\n",
    "- Q: Of the names represented in the data, find the name that has had the largest percentage increase in popularity since 1980. Largest decrease?"
   ],
   "id": "3c2b24e263176988"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:55:00.643102Z",
     "start_time": "2025-07-11T16:54:59.720708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the total births for each year\n",
    "total_births_per_year = names_df.groupby(['Birth_year'])['Name_occurrence'].sum().reset_index()\n",
    "total_births_per_year.rename({'Name_occurrence': 'Total_births'}, axis=1, inplace=True)\n",
    "\n",
    "# Merge total births back into the main dataframe\n",
    "names_df = pd.merge(names_df,total_births_per_year,on='Birth_year')\n",
    "\n",
    "\"\"\"\n",
    "This allows us to compare the number of times a name appeared vs the number of births that year\n",
    "\"\"\"\n",
    "\n",
    "# Calculate the popularity of each name\n",
    "names_df['Popularity'] = (names_df['Name_occurrence'] / names_df['Total_births'])\n",
    "\n",
    "# Sum the popularity of name for each year regardless of gender\n",
    "name_popularity = names_df.groupby(['Birth_year','Name'])['Popularity'].sum().reset_index()\n",
    "\n",
    "# Create a range to view the different names over the years\n",
    "start_year = 1980\n",
    "end_year = name_popularity['Birth_year'].max()\n",
    "pop_1980 = name_popularity[name_popularity['Birth_year'] == start_year]\n",
    "pop_end = name_popularity[name_popularity['Birth_year'] == end_year]"
   ],
   "id": "d5557c7031c10ccc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:55:00.680780Z",
     "start_time": "2025-07-11T16:55:00.672967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge using outer so all the names regardless if they showed each year\n",
    "popularity_change_df = pd.merge(\n",
    "    pop_1980[['Name','Popularity']],\n",
    "    pop_end[['Name','Popularity']],\n",
    "    on = 'Name',\n",
    "    how = 'outer',\n",
    "    suffixes = ('_1980','_end')\n",
    ")\n",
    "\n",
    "# Replace NaN with a very small number so we avoid division by zero errors\n",
    "# To show a clear separation between the data and fill a value 1/1000 the size was used\n",
    "popularity_change_df.fillna(1e-9, inplace=True)"
   ],
   "id": "64c76089da6bc6f6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:55:00.702618Z",
     "start_time": "2025-07-11T16:55:00.697700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# To calculate the change, we have to divide the difference in popularity by the oldest value\n",
    "popularity_change_df['Percentage_change'] = (popularity_change_df['Popularity_end'] - popularity_change_df['Popularity_1980']) / popularity_change_df['Popularity_1980'] * 100\n",
    "\n",
    "# Sort the popularity change in descending order\n",
    "# Print the 10 largest increases\n",
    "increase_sorted = popularity_change_df.sort_values(by=['Percentage_change'], ascending=False)\n",
    "print(f'Largest popularity increase: {start_year} - {end_year}')\n",
    "print(increase_sorted.head(10))"
   ],
   "id": "69892df796a39658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest popularity increase: 1980 - 2021\n",
      "          Name  Popularity_1980  Popularity_end  Percentage_change\n",
      "4380    Harper     1.000000e-09        0.003015       3.015064e+08\n",
      "306      Aiden     1.000000e-09        0.002934       2.933652e+08\n",
      "2059    Camila     1.000000e-09        0.002842       2.842287e+08\n",
      "4541    Hudson     1.000000e-09        0.002714       2.713593e+08\n",
      "5130    Jayden     1.000000e-09        0.002479       2.479313e+08\n",
      "7138      Luca     1.000000e-09        0.002454       2.454427e+08\n",
      "7719  Maverick     1.000000e-09        0.002343       2.342798e+08\n",
      "7284   Madison     1.000000e-09        0.002110       2.109940e+08\n",
      "5104     Jaxon     1.000000e-09        0.002024       2.023907e+08\n",
      "4708      Isla     1.000000e-09        0.001960       1.960271e+08\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:55:00.743139Z",
     "start_time": "2025-07-11T16:55:00.726896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Determine how many times a name was used in 1980\n",
    "counts_1980 = names_df[names_df['Birth_year'] == 1980].groupby('Name')['Name_occurrence'].sum().reset_index()\n",
    "counts_1980\n",
    "\n",
    "# Merge the 1980 data onto main dataframe to get a better idea of which names have decreased in popularity since that year\n",
    "popularity_change_df = pd.merge(popularity_change_df,counts_1980, on = 'Name', how = 'left')\n",
    "popularity_change_df.fillna(0, inplace=True)"
   ],
   "id": "6a346bedf7e91a9f",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:55:00.765162Z",
     "start_time": "2025-07-11T16:55:00.762484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter for names that by occurrence to get rid of statistical noise (remove the rare names).\n",
    "# Sort the names in ascending order to better see the name with the greatest percentage decrease\n",
    "meaningful_names_df = popularity_change_df[popularity_change_df['Name_occurrence'] >= 1000]\n",
    "decrease_sorted = meaningful_names_df.sort_values(by='Percentage_change', ascending=True)"
   ],
   "id": "a37b1fceadd2fa1b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T16:55:00.789052Z",
     "start_time": "2025-07-11T16:55:00.785501Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Largest popularity decrease: {start_year} - {end_year}')\n",
    "print(decrease_sorted.head(10))"
   ],
   "id": "11f48e593b4ae593",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest popularity decrease: 1980 - 2021\n",
      "          Name  Popularity_1980  Popularity_end  Percentage_change  \\\n",
      "10828    Tonya         0.000982    1.000000e-09         -99.999898   \n",
      "1656      Beth         0.000908    1.000000e-09         -99.999890   \n",
      "6434    Kristi         0.000805    1.000000e-09         -99.999876   \n",
      "7909   Michele         0.000798    1.000000e-09         -99.999875   \n",
      "6713    Latoya         0.000793    1.000000e-09         -99.999874   \n",
      "1765      Brad         0.000756    1.000000e-09         -99.999868   \n",
      "10565    Tasha         0.000721    1.000000e-09         -99.999861   \n",
      "6686   Latasha         0.000652    1.000000e-09         -99.999847   \n",
      "3271     Ebony         0.000502    1.000000e-09         -99.999801   \n",
      "9222    Rhonda         0.000484    1.000000e-09         -99.999793   \n",
      "\n",
      "       Name_occurrence  \n",
      "10828           3075.0  \n",
      "1656            2844.0  \n",
      "6434            2521.0  \n",
      "7909            2499.0  \n",
      "6713            2482.0  \n",
      "1765            2368.0  \n",
      "10565           2256.0  \n",
      "6686            2042.0  \n",
      "3271            1572.0  \n",
      "9222            1515.0  \n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Part 5\n",
    "\n",
    "- Can you identify names that may have had an even larger increase or decrease in popularity?"
   ],
   "id": "bc1eb1f9c5a51077"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T17:33:31.773963Z",
     "start_time": "2025-07-11T17:33:31.771321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import linregress\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ],
   "id": "9535b485cac144b0",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T17:34:00.284115Z",
     "start_time": "2025-07-11T17:33:58.201460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to calculate the slope of name popularity over time\n",
    "def calculate_slope(group):\n",
    "    \"\"\"\n",
    "    Fits a linear regression to the popularity trend of a name over time.\n",
    "\n",
    "    Parameters:\n",
    "        group (DataFrame): Subset of data for one name, with columns 'Birth_year' and 'Popularity'.\n",
    "\n",
    "    Returns:\n",
    "        float: The slope of the regression line (indicating trend direction and strength).\n",
    "    \"\"\"\n",
    "    return linregress(x=group['Birth_year'], y=group['Popularity'])[0]\n",
    "\n",
    "# Inform the user that the slope calculation is starting\n",
    "print('Calculating the slopes for each name...')\n",
    "\n",
    "# Apply the slope calculation to each name group\n",
    "slopes = name_popularity.groupby('Name').apply(calculate_slope)\n",
    "\n",
    "# Convert the Series to a DataFrame and drop names with NaN slopes\n",
    "slopes_df = slopes.reset_index(name='Slope').dropna()\n",
    "\n",
    "# Preview: 5 names with steepest **decline** in popularity (most negative slope)\n",
    "print(\"\\nTop 5 Declining Names:\")\n",
    "print(slopes_df.sort_values(by='Slope', ascending=True).head())\n",
    "\n",
    "# Preview: 5 names with steepest **increase** in popularity (most positive slope)\n",
    "print(\"\\nTop 5 Rising Names:\")\n",
    "print(slopes_df.sort_values(by='Slope', ascending=False).head())\n"
   ],
   "id": "705974dc5280724",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the slopes for each name...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_stats_mstats_common.py:182: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope = ssxym / ssxm\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_stats_mstats_common.py:196: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/stats/_stats_mstats_common.py:199: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Declining Names:\n",
      "          Name     Slope\n",
      "20630     Mary -0.000391\n",
      "14747     John -0.000269\n",
      "25279   Robert -0.000255\n",
      "13374    James -0.000233\n",
      "31023  William -0.000206\n",
      "\n",
      "Top 5 Rising Names:\n",
      "          Name     Slope\n",
      "655      Aiden  0.000173\n",
      "13900   Jayden  0.000161\n",
      "10020   Everly  0.000135\n",
      "16342  Kehlani  0.000115\n",
      "13861    Jaxon  0.000106\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d9a1bf9fe1e3b73"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
